---
lab:
  title: An√°lisis y depuraci√≥n de la aplicaci√≥n de IA generativa con seguimiento
---

# An√°lisis y depuraci√≥n de la aplicaci√≥n de IA generativa con seguimiento

Este ejercicio dura aproximadamente¬†**30**¬†minutos.

> **Nota**: en este ejercicio se presupone que tienes alg√∫n conocimiento de Fundici√≥n de IA de Azure, por lo que algunas instrucciones son intencionadamente menos detalladas para fomentar la exploraci√≥n m√°s activa y el aprendizaje pr√°ctico.

## Introducci√≥n

En este ejercicio, ejecutar√°s un asistente de IA generativa de varios pasos que recomienda excursiones de senderismo y sugiere equipo de excursionismo. Usar√°s las caracter√≠sticas de seguimiento del SDK de inferencia de Azure AI para analizar c√≥mo se ejecuta la aplicaci√≥n e identificar los puntos de decisi√≥n clave tomados por el modelo y la l√≥gica circundante.

Interactuar√°s con un modelo implementado para simular el recorrido real del usuario, realizar un seguimiento de cada fase de la aplicaci√≥n desde la entrada de usuario a la respuesta del modelo al procesamiento posterior y ver√°s los datos de seguimiento en Fundici√≥n de IA de Azure. Esto te ayudar√° a comprender c√≥mo el seguimiento mejora la observabilidad, simplifica la depuraci√≥n y apoya la optimizaci√≥n del rendimiento de las aplicaciones de IA generativa.

## Configuraci√≥n del entorno

Para completar las tareas de este ejercicio, necesitas:

- Un centro de Fundici√≥n de IA de Azure,
- Un proyecto de Fundici√≥n de IA de Azure,
- Un modelo implementado (como GPT-4o),
- Un recurso de Application Insights conectado.

### Creaci√≥n de un centro y un proyecto de Fundici√≥n de IA de Azure

Para configurar r√°pidamente un centro y un proyecto, se proporcionan instrucciones sencillas para usar la interfaz de usuario del Portal de la Fundici√≥n de IA de Azure.

1. Ve al Portal de la Fundici√≥n de IA de Azure: abre [https://ai.azure.com](https://ai.azure.com).
1. Inicie sesi√≥n con sus credenciales de Azure.
1. Crear un proyecto:
    1. Ve a **Todos los centros y proyectos**.
    1. Selecciona **+ Nuevo proyecto**.
    1. Escribe un **nombre de proyecto**.
    1. Cuando se te solicite, **crea un nuevo centro**.
    1. Personalizaci√≥n del centro:
        1. Selecciona **Suscripci√≥n**, **Grupo de recursos**, **Ubicaci√≥n**, etc.
        1. Conecta un nuevo recurso de **Servicio de Azure AI** (omite B√∫squeda de AI).
    1. Revise y seleccione **Crear**.
1. **Espera unos minutos a que se complete la implementaci√≥n** (~ 1-2 minutos).

### Implementaci√≥n de un modelo

Para generar datos que puedas supervisar, primero deber√°s implementar un modelo e interactuar con √©l. En las instrucciones se te pide que implementes un modelo GPT-4o, pero **puedes usar cualquier modelo** de la colecci√≥n de Azure OpenAI Service que est√© disponible.

1. En el men√∫ de la izquierda, en la secci√≥n **Mis recursos**, selecciona la p√°gina **Modelos y puntos de conexi√≥n**.
1. Implementa un **modelo base** y elige **gpt-4o**.
1. **Personaliza los detalles de implementaci√≥n**.
1. Establece la **capacidad** en **5000 tokens por minuto (TPM).**

El centro y el proyecto est√°n listos, todos los recursos de Azure necesarios se han aprovisionado autom√°ticamente.

### Conectar Application Insights

Conecta Application Insights al proyecto en Fundici√≥n de IA de Azure para empezar a recopilar datos para su an√°lisis.

1. Abre el proyecto en el Portal de la Fundici√≥n de IA de Azure.
1. Usa el men√∫ de la izquierda y selecciona la p√°gina **Seguimiento**.
1. **Crea un nuevo** recurso de Application Insights para conectarse a la aplicaci√≥n.
1. Escribe el **nombre del recurso de Application Insights**.

Application Insights ahora est√° conectado al proyecto y los datos comenzar√°n a recopilarse para su an√°lisis.

## Ejecuci√≥n de una aplicaci√≥n de IA generativa con Cloud Shell

Te conectar√°s al proyecto de Fundici√≥n de IA de Azure desde Azure Cloud Shell e interactuar√°s mediante programaci√≥n con un modelo implementado como parte de una aplicaci√≥n de IA generativa.

### Interacci√≥n con un modelo implementado

Empieza por recuperar la informaci√≥n necesaria para autenticarte para interactuar con el modelo implementado. A continuaci√≥n, acceder√°s a Azure Cloud Shell y actualizar√°s el c√≥digo de la aplicaci√≥n de IA generativa.

1. En el Portal de la Fundici√≥n de IA de Azure, mira la p√°gina **Informaci√≥n general** del proyecto.
1. En el √°rea **Detalles del proyecto**, anota la **Cadena de conexi√≥n del proyecto**.
1. **Guarda** la cadena en un Bloc de notas. Usar√°s esta cadena de conexi√≥n para conectarte al proyecto en una aplicaci√≥n cliente.
1. Abre una nueva pesta√±a del explorador (mant√©n el Portal de la Fundici√≥n de IA de Azure abierto en la pesta√±a existente).
1. En la nueva pesta√±a, explora [Azure Portal](https://portal.azure.com) en `https://portal.azure.com` e inicia sesi√≥n con tus credenciales de Azure, si se te solicita.
1. Usa el bot√≥n **[\>_]** situado a la derecha de la barra de b√∫squeda en la parte superior de la p√°gina para crear una nueva instancia de Cloud Shell en Azure Portal, para lo que deber√°s seleccionar un entorno de ***PowerShell*** sin almacenamiento en tu suscripci√≥n.
1. En la barra de herramientas de Cloud Shell, en el men√∫ **Configuraci√≥n**, selecciona **Ir a la versi√≥n cl√°sica**.

    **<font color="red">Aseg√∫rate de que has cambiado a la versi√≥n cl√°sica de Cloud Shell antes de continuar.</font>**

1. En el panel de Cloud Shell, escribe y ejecuta los comandos siguientes:

    ```
    rm -r mslearn-genaiops -f
    git clone https://github.com/microsoftlearning/mslearn-genaiops mslearn-genaiops
    ```

    Este comando clona el repositorio de GitHub que contiene los archivos de c√≥digo de este ejercicio.

1. Una vez clonado el repo, ve a la carpeta que contiene los archivos de c√≥digo de aplicaci√≥n:  

    ```
   cd mslearn-genaiops/Files/08
    ```

1. En el panel de la l√≠nea de comandos de Cloud Shell, escribe el siguiente comando para instalar las bibliotecas que necesitas:

    ```
   python -m venv labenv
   ./labenv/bin/Activate.ps1
   pip install python-dotenv azure-identity azure-ai-projects azure-ai-inference azure-monitor-opentelemetry
    ```

1. Escribe el siguiente comando para abrir el archivo de configuraci√≥n que se ha proporcionado:

    ```
   code .env
    ```

    El archivo se abre en un editor de c√≥digo.

1. En el archivo de c√≥digo:

    1. Reemplaza el marcador de posici√≥n **your_project_connection_string** por la cadena de conexi√≥n del proyecto (copiado de la p√°gina **Informaci√≥n general** del proyecto en el Portal de la Fundici√≥n de IA de Azure).
    1. Reemplaza el marcador de posici√≥n **your_model_deployment** por el nombre que asignaste a la implementaci√≥n del modelo gpt-4o (de manera predeterminada `gpt-4o`).

1. *Despu√©s* de reemplazar los marcadores de posici√≥n, en el editor de c√≥digo, usa el comando **CTRL+S** o **haz clic con el bot√≥n derecho y luego en Guardar** para **guardar los cambios**.

### Actualizaci√≥n del c√≥digo de la aplicaci√≥n de IA generativa

Ahora que tanto el entorno como el archivo .env est√°n configurados, es el momento de preparar el script del asistente de IA para su ejecuci√≥n. Junto a la conexi√≥n con un proyecto de IA y la habilitaci√≥n de Application Insights, debes:

- Interactuar con el modelo implementado.
- Definir la funci√≥n para especificar la indicaci√≥n.
- Definir el flujo principal que llama a todas las funciones.

Agregar√° estas tres partes a un script inicial.

1. Ejecuta el siguiente comando para **abrir el script** que se ha proporcionado:

    ```
   code start-prompt.py
    ```

    Ver√°s que varias l√≠neas clave se han dejado en blanco o se han marcado con # comentarios vac√≠os. La tarea consiste en completar el script copiando y pegando las l√≠neas correctas a continuaci√≥n en las ubicaciones adecuadas.

1. En el script, busca **# Function to call the model and handle tracing**.
1. Pega el siguiente c√≥digo debajo de este comentario:

    ```
   def call_model(system_prompt, user_prompt, span_name):
        with tracer.start_as_current_span(span_name) as span:
            span.set_attribute("session.id", SESSION_ID)
            span.set_attribute("prompt.user", user_prompt)
            start_time = time.time()
    
            response = chat_client.complete(
                model=model_name,
                messages=[SystemMessage(system_prompt), UserMessage(user_prompt)]
            )
    
            duration = time.time() - start_time
            output = response.choices[0].message.content
            span.set_attribute("response.time", duration)
            span.set_attribute("response.tokens", len(output.split()))
            return output
    ```

1. En el script, busca **# Function to recommend a hike based on user preferences**.
1. Pega el siguiente c√≥digo debajo de este comentario:

    ```
   def recommend_hike(preferences):
        with tracer.start_as_current_span("recommend_hike") as span:
            prompt = f"""
            Recommend a named hiking trail based on the following user preferences.
            Provide only the name of the trail and a one-sentence summary.
            Preferences: {preferences}
            """
            response = call_model(
                "You are an expert hiking trail recommender.",
                prompt,
                "recommend_model_call"
            )
            span.set_attribute("hike_recommendation", response.strip())
            return response.strip()
    ```

1. En el script, busca **# ---- Main Flow ----**.
1. Pega el siguiente c√≥digo debajo de este comentario:

    ```
   if __name__ == "__main__":
       with tracer.start_as_current_span("trail_guide_session") as session_span:
           session_span.set_attribute("session.id", SESSION_ID)
           print("\n--- Trail Guide AI Assistant ---")
           preferences = input("Tell me what kind of hike you're looking for (location, difficulty, scenery):\n> ")

           hike = recommend_hike(preferences)
           print(f"\n‚úÖ Recommended Hike: {hike}")

           # Run profile function


           # Run match product function


           print(f"\nüîç Trace ID available in Application Insights for session: {SESSION_ID}")
    ```

1. **Guarda los cambios** realizados en el script.
1. En el panel de l√≠nea de comandos de Cloud Shell, debajo del editor de c√≥digo, escribe el siguiente comando para **ejecutar el script**:

    ```
   python start-prompt.py
    ```

1. Proporciona una descripci√≥n del tipo de caminata que est√°s buscando, por ejemplo:

    ```
   A one-day hike in the mountains
    ```

    El modelo generar√° una respuesta, que se capturar√° con Application Insights. Puedes visualizar los seguimientos en el **Portal de la Fundici√≥n de IA de Azure**.

> **Nota**: los datos de supervisi√≥n pueden tardar unos minutos en mostrarse en Azure Monitor.

## Visualizaci√≥n de los datos de seguimiento en el Portal de la Fundici√≥n de IA de Azure

Despu√©s de ejecutar el script, capturaste un seguimiento de la ejecuci√≥n de la aplicaci√≥n de IA. Ahora lo explorar√°s con Application Insights en Fundici√≥n de IA de Azure.

> **Nota:** m√°s adelante, volver√°s a ejecutar el c√≥digo y volver√°s a ver los seguimientos en el Portal de la Fundici√≥n de IA de Azure. Vamos a explorar primero d√≥nde encontrar los seguimientos para visualizarlos.

### Ve al Portal de la Fundici√≥n de IA de Azure

1. **¬°No cierres Cloud Shell!** Volver√°s a esto para actualizar el c√≥digo y volverlo a ejecutar.
1. Ve a la pesta√±a del explorador con el **Portal de la Fundici√≥n de IA de Azure** abierto.
1. Usa el men√∫ de la izquierda y selecciona **Seguimiento**.
1. *Si* no se muestra ning√∫n dato, **actualiza** la vista.
1. Selecciona el seguimiento **train_guide_session** para abrir una nueva ventana que muestre m√°s detalles.

### Revisi√≥n del seguimiento

En esta vista se muestra el seguimiento de una sesi√≥n completa del asistente de IA de la gu√≠a de senderos.

- **Intervalo de nivel superior**: trail_guide_session Este es el intervalo primario. Representa la ejecuci√≥n completa del asistente de principio a fin.

- **Intervalos secundarios anidados**: cada l√≠nea con sangr√≠a representa una operaci√≥n anidada. Encontrar√°s lo siguiente:

    - **recommend_hike** que captura la l√≥gica para decidir una caminata.
    - **recommend_model_call** que es el intervalo creado por call_model() dentro de recommend_hike.
    - **chat gpt-4o** que el SDK de inferencia de Azure AI instrumenta autom√°ticamente para mostrar la interacci√≥n real de LLM.

1. Puedes hacer clic en cualquier intervalo para ver:

    1. La duraci√≥n.
    1. Sus atributos, como la indicaci√≥n del usuario, los tokens usados, el tiempo de respuesta.
    1. Cualquier error o datos personalizados adjuntos con **span.set_attribute(...)**.

## Adici√≥n de m√°s funciones al c√≥digo


1. Escribe el siguiente comando para **volver a abrir el script**:

    ```
   code start-prompt.py
    ```

1. En el script, busca **# Function to generate a trip profile for the recommended hike**.
1. Pega el siguiente c√≥digo debajo de este comentario:

    ```
   def generate_trip_profile(hike_name):
       with tracer.start_as_current_span("trip_profile_generation") as span:
           prompt = f"""
           Hike: {hike_name}
           Respond ONLY with a valid JSON object and nothing else.
           Do not include any intro text, commentary, or markdown formatting.
           Format: {{ "trailType": ..., "typicalWeather": ..., "recommendedGear": [ ... ] }}
           """
           response = call_model(
               "You are an AI assistant that returns structured hiking trip data in JSON format.",
               prompt,
               "trip_profile_model_call"
           )
           print("üîç Raw model response:", response)
           try:
               profile = json.loads(response)
               span.set_attribute("profile.success", True)
               return profile
           except json.JSONDecodeError as e:
               print("‚ùå JSON decode error:", e)
               span.set_attribute("profile.success", False)
               return {}
    ```

1. En el script, busca **# Function to match recommended gear with products in the catalog**.
1. Pega el siguiente c√≥digo debajo de este comentario:

    ```
   def match_products(recommended_gear):
       with tracer.start_as_current_span("product_matching") as span:
           matched = []
           for gear_item in recommended_gear:
               for product in mock_product_catalog:
                   if any(word in product.lower() for word in gear_item.lower().split()):
                       matched.append(product)
                       break
           span.set_attribute("matched.count", len(matched))
           return matched
    ```

1. En el script, busca **# Run profile function**.
1. Debajo y **alineado con** este comentario, pega el c√≥digo siguiente:

    ```
           profile = generate_trip_profile(hike)
           if not profile:
           print("Failed to generate trip profile. Please check Application Insights for trace.")
           exit(1)

           print(f"\nüìã Trip Profile for {hike}:")
           print(json.dumps(profile, indent=2))
    ```

1. En el script, busca **# Run match product function**.
1. Debajo y **alineado con** este comentario, pega el c√≥digo siguiente:

    ```
           matched = match_products(profile.get("recommendedGear", []))
           print("\nüõí Recommended Products from Lakeshore Retail:")
           print("\n".join(matched))
    ```

1. **Guarda los cambios** realizados en el script.
1. En el panel de l√≠nea de comandos de Cloud Shell, debajo del editor de c√≥digo, escribe el siguiente comando para **ejecutar el script**:

    ```
   python start-prompt.py
    ```

1. Proporciona una descripci√≥n del tipo de caminata que est√°s buscando, por ejemplo:

    ```
   I want to go for a multi-day adventure along the beach
    ```

> **Nota**: los datos de supervisi√≥n pueden tardar unos minutos en mostrarse en Azure Monitor.

### Visualizaci√≥n de los nuevos seguimientos en el Portal de la Fundici√≥n de IA de Azure

1. Vuelve al Portal de la Fundici√≥n de IA de Azure.
1. Deber√≠a aparecer un nuevo seguimiento con el mismo nombre **trail_guide_session**. Actualiza la vista si es necesario.
1. Selecciona el nuevo seguimiento para abrir una vista m√°s detallada.
1. Revisa los nuevos intervalos secundarios anidados **trip_profile_generation** y **product_matching**.
1. Selecciona **product_matching** y revisa los metadatos que aparecen.

    En la funci√≥n product_matching, inclu√≠ste **span.set_attribute("matched.count", len(matched)))**. Al establecer el atributo con el par clave-valor **matched.count** y la longitud de la variable coincidente, agregaste esta informaci√≥n al seguimiento de **product_matching**. Puedes encontrar este par clave-valor en **atributos** en los metadatos.

## (OPCIONAL) Seguimiento de un error

Si tienes tiempo adicional, puedes revisar c√≥mo usar seguimientos cuando tengas un error. Se proporciona un script que probablemente produzca un error. Ejec√∫talo y revisa los seguimientos.

Se trata de un ejercicio dise√±ado para representar un desaf√≠o, lo que significa que las instrucciones son intencionadamente menos detalladas.

1. En Cloud Shell, abre el script **error-prompt.py**. Este script se encuentra en el mismo directorio que el script **start-prompt.py**. Revisa el contenido.
1. Ejecuta el script **error-prompt.py**. Proporciona una respuesta en la l√≠nea de comandos cuando se te solicite.
1. *Esperamos* que el mensaje de salida incluya **No se pudo generar el perfil de viaje. Consulta Application Insights para el seguimiento.**.
1. Vaya al seguimiento de **trip_profile_generation** e inspecciona por qu√© se produjo un error.

<br>
<details>
<summary><b>Obtener la respuesta sobre</b>: ¬øPor qu√© puedes haber experimentado un error...</summary><br>
<p>Si inspeccionas el seguimiento de LLM para la funci√≥n generate_trip_profile, observar√°s que la respuesta del asistente incluye acentos pendientes y la palabra json para dar formato a la salida como un bloque de c√≥digo.

Aunque esto resulta √∫til para mostrar, provoca problemas en el c√≥digo porque la salida ya no es JSON v√°lido. Esto produce un error de an√°lisis durante el procesamiento posterior.

Es probable que el error se deba a c√≥mo se indica a LLM que se ajuste a un formato espec√≠fico para su salida. La inclusi√≥n de las instrucciones en la indicaci√≥n del usuario aparece m√°s eficaz que colocarla en el aviso del sistema.</p>
</details>

## D√≥nde encontrar otros laboratorios

Puedes explorar laboratorios y ejercicios adicionales en el [Portal de aprendizaje de la Fundici√≥n de IA de Azure](https://ai.azure.com) o consultar la **secci√≥n de laboratorio** del curso para ver otras actividades disponibles.
